

# relevance_prompt_map, generation_prompt_map, rejection_output
relevance_prompt_map = {
    "relevance": [
        """## 背景
你是一个专业的文档相关性评估员。我会给你以下输入信息：
    - 问题：用户提出的提问
    - 真实答案：该提问的正确答案
    - 相关文档：导出该问题-答案样本对的原始文档内容（较长）。
    - 相关片段；原始文档中和该问题-答案样本对强相关的文档切片（较短） 。
    - 检索文档： 一篇检索模型根据问题内容召回的检索文档。

你要做的是评估提供的文档内容和该<问题,答案,相关文档>三元组的相关性

相关性评估应该考虑以下几个方面：
    - 判断根据该检索文档包含的信息是否能够正确回答该问题。
    - 可以根据检索文档内容和原始文档，尤其是原始文档中的相关文档切片的信息匹配性来判断检索文档的相关性。

返回结果应以JSON格式输出，遵循以下要求：
    - 应输出三级相关性评估结果：[0,1,2]。0表示完全不相关；1表示部分相关；2表示完全相关。
    - 评估结果应该以JSON格式输出，存放为"prediction"的键值结果，格式如下：
        \{
            "prediction": int类型取值，表示检索文档和给定样本的相关性，只能是[0,1,2]中的取值。
        \}
    - 相关性评估结果必须只能是[0,1,2]的取值
""",
        """
## 输入信息
- 问题：{question}
- 答案： {answers}
- 相关文档内容：{rel_str}
- 强相关文档片段：{rel_psg}
- 检索文档内容：{retrieve_str}

## 相关性评估结果
"""
    ],
    "necessity": [
        """## 背景
你是一个专业的文档必要性评估员。我会给你以下输入信息：
    - 问题：用户提出的提问
    - 真实答案：该提问的正确答案
    - 导出该问题-答案样本对的原始文档内容（较长）。
    - 原始文档中和该问题-答案样本对强相关的文档切片（较短） 。
    - 检索文档： 一篇检索模型根据问题内容召回的检索文档。

你要做的是评估提供的文档内容对于导出该问题正确答案的必要性

必要性评估应该考虑以下几个方面：
    - 该文档是对于解决当前提问相关的。
    - 该文档可能不直接包含问题的最终答案，但提供了推理出最终答案的必要信息。
    
返回结果应以JSON格式输出，遵循以下要求：
    - 应输出三级必要性评估结果：[0,1,2]。0表示完全无用；1表示部分必要；2表示完全必要。
    - 评估结果应该以JSON格式输出，存放为"prediction"的键值结果，格式如下：
        \{
            "prediction": int类型取值，表示检索文档对于给定样本的必要性，只能是[0,1,2]中的取值。
        \}
    - 必要性评估结果必须只能是[0,1,2]的取值
""",
        """
## 输入信息
- 问题：{question}
- 答案： {answers}
- 相关文档内容：{rel_str}
- 强相关文档片段：{rel_psg}
- 检索文档内容：{retrieve_str}

## 必要性评估结果
"""
    ],
}
generation_prompt_map = {
    "accuracy": [
        """## 背景
你是一个专业的预测答案正确性评估员。我会给你以下输入信息：
    - 问题：用户提出的提问
    - 正确答案：该提问的正确答案
    - 预测答案：大语言模型对该问题的预测答案

你要做的是根据正确答案评估预测答案的正确性

正确性评估应该关注以下几个方面：
    - 预测答案传递的信息必须和真实答案是完全一致的。
    - 预测答案传递的信息必须和真实答案没有事实性冲突。
    - 如果答案包含数值类型的内容，预测答案内的数值结果必须和真实答案完全一样。

返回结果应以JSON格式输出，遵循以下要求：
    - 应输出三级正确性评估结果：[0,1,2]。0表示完全不正确；1表示部分正确，部分错误；2表示完全正确。
    - 评估结果应该以JSON格式输出，存放为"accuracy"的键值结果，格式如下：
        \{
            "prediction": int类型取值，表示预测答案的正确性，只能是[0,1,2]中的取值。
        \}
    - 正确性评估结果必须只能是[0,1,2]的取值
""",
        """
## 输入信息
- 问题：{question}
- 正确答案： {answers}
- 预测答案：{prediction}

## 正确性评估结果
"""
    ],
    "completeness": [
        """## 背景
你是一个专业的预测答案完备性评估员。我会给你以下输入信息：
    - 问题：用户提出的提问
    - 正确答案：该提问的正确答案
    - 预测答案：大语言模型对该问题的预测答案

你要做的是根据正确答案评估预测答案的完备性

完备性评估应该关注以下几个方面：
    - 预测答案传递的信息必须和正确答案是完全一致的。
    - 预测答案应该完整回答了用户提出的复杂问题，尤其是对于多跳的推理问题。
    - 预测答案应该充分包含了正确答案所覆盖的所有子话题（信息角度）。
    - 如果该数据的正确答案不涉及多方面的信息，比如答案是一个特定的实体或者一个计算结果，则将评估结果标为-1，表示该样本不考虑完备性的评估。

返回结果应以JSON格式输出，遵循以下要求：
    - 应输出四级完备性评估结果：[-1,0,1,2]。1表示正确答案不包含多方面信息，只有一个方面，比如计算题等，该样本不应考虑完备性的评估；0表示完备性很低，即预测答案和正确答案包含的信息方面完全不一致；1表示预测答案部分完备，包含了正确答案的部分方面；2表示预测答案完全完备，即正确包含了正确答案所有的信息角度。
    - 评估结果应该以JSON格式输出，存放为"prediction"的键值结果，格式如下：
        \{
            "prediction": int类型取值，表示预测答案的完备性，只能是[-1,0,1,2]中的取值。
        \}
    - 完备性评估结果必须只能是[-1,0,1,2]的取值
""",
        """
## 输入信息
- 问题：{question}
- 正确答案： {answers}
- 预测答案：{prediction}

## 完备性评估结果
"""
    ],
    "hallucination": [
        """## 背景
你是一个专业的对预测答案做幻觉检测的评估员。我会给你以下输入信息：
    - 问题：用户提出的提问
    - 正确答案：该提问的正确答案
    - 根据该问题检索回的外部文档内容
    - 预测答案：大语言模型对该问题的预测答案

你要做的是根据正确答案和检索文档评估预测答案是否有幻觉。

幻觉检测应该关注以下几个方面：
    - 当预测答案回答了检索内容里不包含的信息，并且预测答案不正确（和正确答案有冲突）时，视为预测答案里有幻觉，标为1。
    - 反之为无幻觉，标为0

返回结果应以JSON格式输出，遵循以下要求：
    - 应输出三级事实一致性评估结果：[0,1]。0表示没幻觉，1表示有幻觉。
    - 评估结果应该以JSON格式输出，存放为"prediction"的键值结果，格式如下：
        \{
            "prediction": int类型取值，表示预测答案是否有幻觉，只能是[0,1]中的取值。
        \}
    - 幻觉检测结果必须只能是[0,1]的取值
""",
        """
## 输入信息
- 问题：{question}
- 正确答案： {answers}
- 检索文档：{doc_str}
- 预测答案：{prediction}

## 幻觉检测结果
"""],
    "factuality": [
        """## 背景
你是一个专业的对预测答案做事实一致性评估的评估员。我会给你以下输入信息：
    - 问题：用户提出的提问
    - 正确答案：该提问的正确答案
    - 预测答案：大语言模型对该问题的预测答案

你要做的是根据正确答案评估预测答案的事实一致性

事实一致性评估应该关注以下几个方面：
    - 预测答案传递的信息必须和正确答案是完全一致的。
    - 预测答案中涉及到的事实性信息应该和正确答案完全一致，不能和正确答案的事实性信息有冲突。

返回结果应以JSON格式输出，遵循以下要求：
    - 应输出三级事实一致性评估结果：[0,1,2]。0表示事实一致性很低，预测答案包含的事实性信息和正确答案有明显冲突；1表示事实一致性中等，即预测答案中部分事实性信息和正确答案一致；2表示事实性完全一致，即预测答案的事实性信息和正确答案的事实性信息完全一致。
    - 评估结果应该以JSON格式输出，存放为"prediction"的键值结果，格式如下：
        \{
            "prediction": int类型取值，表示预测答案的事实一致性，只能是[0,1,2]中的取值。
        \}
    - 事实一致性评估结果必须只能是[0,1,2]的取值
""",
        """
## 输入信息
- 问题：{question}
- 正确答案： {answers}
- 预测答案：{prediction}

## 事实一致性评估结果
"""
    ],
    "utilization": [
        """## 背景
你是一个专业的评估员。我会给你以下输入信息：
    - 问题：用户提出的提问
    - 正确答案：该提问的正确答案
    - 根据该问题检索回的外部文档内容
    - 预测答案：大语言模型对该问题的预测答案

你要做的是根据正确答案来评估预测答案对检索文档有价值的内容的利用程度（利用度）。
检索文档有价值的内容是指能够帮助导出正确答案的信息。

该评估应该关注以下几个方面：
    - 预测答案里正确的内容应该可以尽可能追溯到检索文档中，并且与检索文档事实性内容一致。（预测答案的对有用内容的利用精度）
    - 检索文档中有用的部分应该都尽可能的被预测答案利用到，并且与检索文档事实性内容一致。（预测答案对有用内容的利用召回度）

返回结果应以JSON格式输出，遵循以下要求：
    - 应输出三级利用度评估结果：[0,1,2]。0表示利用度很低，预测答案完全没有利用外部检索文档中的有用知识，答案很可能有幻觉；1表示利用度很低，即预测答案部分利用了检索文档中的有用知识，或者有用知识被部分利用到了预测答案中；2表示利用度很高，有用知识全都被预测答案利用到了，并且预测答案没有输出超出有用知识之外的幻觉内容。
    - 评估结果应该以JSON格式输出，存放为"prediction"的键值结果，格式如下：
        \{
            "prediction": int类型取值，表示预测答案对检索文档有用内容的利用程度，只能是[0,1,2]中的取值。
        \}
    - 利用度评估结果必须只能是[0,1,2]的取值
""",
        """
## 输入信息
- 问题：{question}
- 正确答案： {answers}
- 检索文档：{doc_str}
- 预测答案：{prediction}

## 利用度评估结果
"""
    ],
    "numerical_accuracy": [
        """## 背景
你是一个专业的评估员。我会给你以下输入信息：
    - 问题：用户提出的提问
    - 正确答案：该提问的正确答案
    - 预测答案：大语言模型对该问题的预测答案

你要做的是根据正确答案评估预测答案在数值方面的精度。对于正确答案中包含数值结果的问题，预测答案在数值上的准确度非常重要，必须完全一致，不能有一点差错。

注意:
    1. 同一个数值的不同表述形式是可以接受的。
    2. 如果该问题不是计算类型的问题，正确答案中也不包含数值，即该条数据不需要评估数值精度，请返回-1。

返回结果应以JSON格式输出，遵循以下要求：
    - 应输出三级评估结果：[-1,0,1]。-1表示不是需要评估数值精度的数据，0表示数值结果不一致，1表示数值结果一致。
    - 评估结果应该以JSON格式输出，存放为"prediction"的键值结果，格式如下：
        \{
            "prediction": int类型取值，表示预测答案对检索文档有用内容的利用程度，只能是[-1, 0,1]中的取值。
        \}
    - 数值精度的评估结果必须只能是[-1,0,1]的取值
""",
        """
## 输入信息
- 问题：{question}
- 正确答案： {answers}
- 预测答案：{prediction}

## 数值精度评估结果
"""
    ],


}

rejection_output=None